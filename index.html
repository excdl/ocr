<!DOCTYPE html>
<html lang="zh-TW">
<head>
<meta charset="UTF-8">
<title>è­·ç…§ / å°èƒè­‰ OCR App (MRZçŸ¯æ­£ + å³æ™‚OCR + æ–‡å­—é‚Šæ¡†)</title>
<script src="https://docs.opencv.org/4.9.0/opencv.js"></script>
<script src="https://unpkg.com/mrz/dist/mrz.min.js"></script>
<style>
body{margin:0;font-family:-apple-system,BlinkMacSystemFont,"Segoe UI",Arial;background:linear-gradient(135deg,#4facfe,#00f2fe);}
.container{width:92%;max-width:900px;margin:28px auto;background:white;border-radius:18px;padding:24px;box-shadow:0 12px 28px rgba(0,0,0,0.15);}
h2{text-align:center;color:#333;}
.upload-box{display:flex;gap:10px;margin-bottom:12px;}
button,label{background:#2979ff;color:white;border:none;padding:12px 18px;border-radius:12px;cursor:pointer;font-size:16px;flex:1;text-align:center;}
.preview-container{display:flex;gap:12px;flex-wrap:wrap;position:relative;}
canvas{border-radius:12px;width:48%;height:auto;background:#eee;}
#status{margin-top:12px;}
pre{background:#222;color:#0f0;padding:12px;border-radius:8px;max-height:200px;overflow:auto;}
</style>
</head>
<body>
<div class="container">
<h2>è­·ç…§ / å°èƒè­‰ OCR App (MRZçŸ¯æ­£ + å³æ™‚OCR + æ–‡å­—é‚Šæ¡†)</h2>
<div class="upload-box">
<input type="file" id="fileInput" accept="image/*" hidden>
<label id="uploadBtn" for="fileInput">ğŸ“¤ ä¸Šå‚³åœ–ç‰‡</label>
<button id="cameraBtn">ğŸ“· ä½¿ç”¨ç›¸æ©Ÿ</button>
</div>

<div class="preview-container">
<canvas id="fullCanvas"></canvas>
<canvas id="mrzCanvas"></canvas>
</div>

<video id="camera" autoplay playsinline style="display:none;"></video>
<button id="capture" style="display:none;margin-top:12px;">ğŸ“¸ æ‹ç…§</button>

<p id="status">è¼‰å…¥ OpenCVâ€¦</p>
<pre id="result">è¾¨è­˜çµæœå°‡é¡¯ç¤ºæ–¼æ­¤</pre>
</div>

<script>
const status = document.getElementById("status");
const fullCanvas = document.getElementById("fullCanvas");
const mrzCanvasElement = document.getElementById("mrzCanvas");
const resultPre = document.getElementById("result");

const GOOGLE_API_KEY = "YOUR_GOOGLE_CLOUD_API_KEY"; // æ›¿æ›æˆä½ çš„ Key
let liveInterval = null;

// MRZ é€è¦–çŸ¯æ­£
function extractMRZRegion(canvas){
    try{
        let src = cv.imread(canvas);
        let gray = new cv.Mat();
        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
        let clahe = new cv.CLAHE(2.0, new cv.Size(8,8));
        let enhanced = new cv.Mat();
        clahe.apply(gray, enhanced);
        let blur = new cv.Mat();
        cv.GaussianBlur(enhanced, blur, new cv.Size(3,3), 0);
        let thresh = new cv.Mat();
        cv.threshold(blur, thresh, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU);

        let contours = new cv.MatVector();
        let hierarchy = new cv.Mat();
        cv.findContours(thresh, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

        let mrzRect = null;
        for(let i=0;i<contours.size();i++){
            let cnt = contours.get(i);
            let rect = cv.boundingRect(cnt);
            if(rect.width>rect.height*5 && rect.y>src.rows*0.5){
                if(!mrzRect || rect.y>mrzRect.y) mrzRect=rect;
            }
        }

        const ctxFull = fullCanvas.getContext('2d');
        fullCanvas.width = canvas.width;
        fullCanvas.height = canvas.height;
        ctxFull.drawImage(canvas,0,0);
        if(mrzRect){
            ctxFull.strokeStyle='red';
            ctxFull.lineWidth=4;
            ctxFull.strokeRect(mrzRect.x, mrzRect.y, mrzRect.width, mrzRect.height);
        }

        let mrzCanvas = mrzCanvasElement;
        if(mrzRect){
            let roi = new cv.Mat(src, new cv.Rect(mrzRect.x,mrzRect.y,mrzRect.width,mrzRect.height));
            let width = roi.cols;
            let height = roi.rows;
            let dst = new cv.Mat();
            let srcTri = cv.matFromArray(4,1,cv.CV_32FC2,[0,0, width,0, width,height, 0,height]);
            let dstTri = cv.matFromArray(4,1,cv.CV_32FC2,[0,0, width,0, width,height, 0,height]); // å¯åŠ æ—‹è½‰æ ¡æ­£
            let M = cv.getPerspectiveTransform(srcTri, dstTri);
            cv.warpPerspective(roi, dst, M, new cv.Size(width,height));

            mrzCanvas.width = width;
            mrzCanvas.height = height;
            cv.imshow(mrzCanvas, dst);

            roi.delete(); srcTri.delete(); dstTri.delete(); M.delete(); dst.delete();
        }

        src.delete(); gray.delete(); enhanced.delete(); blur.delete(); thresh.delete(); contours.delete(); hierarchy.delete(); clahe.delete();
        return mrzCanvas;
    }catch(e){ console.error("MRZåµæ¸¬å¤±æ•—", e); return canvas; }
}

// Google Vision OCR
async function recognizeOCR(canvas){
    const dataURL = canvas.toDataURL("image/png").replace(/^data:image\/(png|jpg);base64,/, "");
    const res = await fetch(`https://vision.googleapis.com/v1/images:annotate?key=${GOOGLE_API_KEY}`, {
        method:"POST",
        body:JSON.stringify({
            requests:[{image:{content:dataURL},features:[{type:"TEXT_DETECTION"}]}]
        })
    });
    const json = await res.json();
    if(json.responses && json.responses[0].textAnnotations && json.responses[0].textAnnotations.length>0){
        return json.responses[0].textAnnotations;
    }
    return [];
}

// è™•ç† MRZ + OCR
async function processCanvas(canvas){
    const mrzCanvas = extractMRZRegion(canvas);
    const annotations = await recognizeOCR(mrzCanvas);
    const ctx = mrzCanvas.getContext('2d');
    ctx.lineWidth=2;
    ctx.strokeStyle='lime';
    ctx.font="18px Arial";
    ctx.fillStyle='lime';

    let result = {};
    if(annotations.length>0){
        const fullText = annotations[0].description.replace(/\s/g,"");
        try{
            const mrz = MRZ.parse(fullText);
            if(mrz.valid){
                result.documentType="Passport";
                result.name=mrz.fields.surname+" "+mrz.fields.givenNames;
                result.id=mrz.fields.documentNumber;
                result.nationality=mrz.fields.nationality;
                result.birthday=mrz.fields.dateOfBirth;
                result.expiry=mrz.fields.expirationDate;
                result.sex=mrz.fields.sex;
            }else{
                result.documentType="Taiwan Compatriot Permit";
                result.raw=annotations.map(a=>a.description).join("\n");
            }
        }catch(e){ result.raw=annotations.map(a=>a.description).join("\n"); }

        // ç•« OCR é‚Šæ¡†
        for(let i=1;i<annotations.length;i++){ // index 0 æ˜¯å…¨æ–‡
            const a = annotations[i];
            const v = a.boundingPoly.vertices;
            ctx.beginPath();
            ctx.moveTo(v[0].x,v[0].y);
            ctx.lineTo(v[1].x,v[1].y);
            ctx.lineTo(v[2].x,v[2].y);
            ctx.lineTo(v[3].x,v[3].y);
            ctx.closePath();
            ctx.stroke();
            ctx.fillText(a.description, v[0].x, v[0].y-2);
        }
    }else{
        resultPre.innerText="OCR ç„¡æ³•è¾¨è­˜";
    }

    resultPre.innerText = JSON.stringify(result,null,2);
}

// ä¸Šå‚³åœ–ç‰‡
document.getElementById("fileInput").onchange = e=>{
    if(e.target.files.length>0){
        const file = e.target.files[0];
        const img = new Image();
        img.onload = ()=>{ processCanvas(img); };
        img.src = URL.createObjectURL(file);
    }
};

// ç›¸æ©Ÿ
const cameraBtn = document.getElementById("cameraBtn");
const camera = document.getElementById("camera");
const capture = document.getElementById("capture");

cameraBtn.onclick = async()=>{
    try{
        const stream = await navigator.mediaDevices.getUserMedia({video:{facingMode:"environment"}});
        camera.srcObject = stream;
        camera.style.display = 'block';
        capture.style.display = 'block';
        if(liveInterval) clearInterval(liveInterval);
        liveInterval = setInterval(async ()=>{
            const tempCanvas = document.createElement('canvas');
            tempCanvas.width = camera.videoWidth;
            tempCanvas.height = camera.videoHeight;
            tempCanvas.getContext('2d').drawImage(camera,0,0);
            extractMRZRegion(tempCanvas); // MRZæ¡†å³æ™‚æ›´æ–°
        },500);
    }catch(e){ console.error("ç›¸æ©Ÿå•Ÿå‹•å¤±æ•—",e); status.innerText="ç„¡æ³•é–‹å•Ÿç›¸æ©Ÿ âŒ"; }
};

capture.onclick = ()=>{
    if(liveInterval){ clearInterval(liveInterval); liveInterval=null; }
    const tempCanvas = document.createElement('canvas');
    tempCanvas.width = camera.videoWidth;
    tempCanvas.height = camera.videoHeight;
    tempCanvas.getContext('2d').drawImage(camera,0,0);
    processCanvas(tempCanvas); // æ‹ç…§å¾Œ OCR
};

if(typeof cv !== 'undefined'){
    cv['onRuntimeInitialized'] = ()=>{ status.innerText="OpenCV è¼‰å…¥å®Œæˆ âœ…"; };
}else{ status.innerText="OpenCV è¼‰å…¥å¤±æ•— âŒ"; }
</script>
</body>
</html>













